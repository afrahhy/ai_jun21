{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('mynewenv': conda)"
  },
  "interpreter": {
   "hash": "7d6121a23a4048d8a7a11f93f07840b870ae7d038dbb65fbcf822b011c54204d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from time import sleep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://www.imdb.com/list/ls009668579/\"\n",
    "#my_driver = r\"C:\\Users\\afrah\\OneDrive\\Documents\\01 STRIVE\\chromedriver.exe\" \n",
    "driver = webdriver.Chrome(r\"C:\\Users\\afrah\\OneDrive\\Documents\\01 STRIVE\\chromedriver.exe\")\n",
    "driver.get(url)\n",
    "sleep(1)\n",
    "\n",
    "databasedictionary = {}\n",
    "\n",
    "ratings =[]\n",
    "for i in range (1, 101):\n",
    "    rating = driver.find_element_by_xpath( '//*[@id=\"main\"]/div/div[3]/div[3]/div[' + str(i) + ']/div[2]/div[1]/div[1]/span[2]')\n",
    "    ratings.append(rating.text)\n",
    "\n",
    "directors = []\n",
    "stars = []\n",
    "for i in range(1, 101):\n",
    "    dirstars = driver.find_element_by_xpath( '//*[@id=\"main\"]/div/div[3]/div[3]/div[' + str(i) + ']/div[2]/p[3]')\n",
    "    dirs = dirstars.text.split('|')[0]\n",
    "    dirs = dirs.split(sep=None, maxsplit=1)[1]\n",
    "    directors.append(dirs)\n",
    "    strs = dirstars.text.split('|')[1]\n",
    "    strs = strs.split(sep=None, maxsplit=1)[1]\n",
    "    stars.append(strs)\n",
    "\n",
    "    \n",
    "metascores = []\n",
    "metascore = driver.find_elements_by_class_name('metascore')\n",
    "for meta in metascore:\n",
    "    metascores.append(meta.text)\n",
    "\n",
    "gross = []\n",
    "for i in range (1, 101):\n",
    "    try:\n",
    "        bogross = driver.find_element_by_xpath( '//*[@id=\"main\"]/div/div[3]/div[3]/div[' + str(i) + ']/div[2]/p[4]/span[5]')\n",
    "        bogross = bogross.text.replace('$', '').replace('M','')\n",
    "        gross.append(bogross.text)\n",
    "    except:\n",
    "        gross.append('Unavailable')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "databasedictionary = {\n",
    "    'Directed by': directors,\n",
    "    'Starring': stars,\n",
    "    'Box Office Gross in Million Dollars': gross,\n",
    "    'Metascore from Metacritic': metascore\n",
    "}   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from time import sleep\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# selenium broswer \n",
    "url = \"https://www.imdb.com/list/ls009668579/\"\n",
    "#my_driver = r\"C:\\Users\\afrah\\OneDrive\\Documents\\01 STRIVE\\chromedriver.exe\" \n",
    "driver = webdriver.Chrome(r\"C:\\Users\\afrah\\OneDrive\\Documents\\01 STRIVE\\chromedriver.exe\")\n",
    "driver.get(url)\n",
    "sleep(1)\n",
    "\n",
    "#soup \n",
    "page = requests.get(url)\n",
    "\n",
    "soup = bs(page.content , \"html.parser\")\n",
    "url = \"https://www.imdb.com/list/ls009668579/\"\n",
    "\n",
    "#list of names and the release dates\n",
    "m_frame = soup.find(\"div\" , class_ = \"lister-list\")\n",
    "m_name = m_frame.findAll(\"h3\", class_=\"lister-item-header\")\n",
    "m_name_list =[name.text.strip().split(\"\\n\") for name in m_name] \n",
    "m_name_list_t = np.array(m_name_list).T.tolist()\n",
    "m_names = m_name_list_t[:][1]\n",
    "m_r_date = m_name_list_t[:][2]\n",
    "#m_r_dates stands for movie dates but it is little bit dirty  this is why im going to replace and strip and split\n",
    "m_r_dates = [i.replace(\"(\",\" \").replace(\")\",\"\").replace(\"I\",\"\").strip() for i in m_r_date]\n",
    "\n",
    "#movie description\n",
    "m_desc = m_frame.findAll(\"p\",class_ =\"\" )\n",
    "m_desc_list = [d.text.strip().split(\"\\n\") for d in m_desc]\n",
    "\n",
    "directors = []\n",
    "stars = []\n",
    "for i in range(1, 101):\n",
    "    dirstars = driver.find_element_by_xpath( '//*[@id=\"main\"]/div/div[3]/div[3]/div[' + str(i) + ']/div[2]/p[3]')\n",
    "    dirs = dirstars.text.split('|')[0]\n",
    "    dirs = dirs.split(sep=None, maxsplit=1)[1]\n",
    "    directors.append(dirs)\n",
    "    strs = dirstars.text.split('|')[1]\n",
    "    strs = strs.split(sep=None, maxsplit=1)[1]\n",
    "    stars.append(strs)\n",
    "\n",
    "    \n",
    "metascores = []\n",
    "metascore = driver.find_elements_by_class_name('metascore')\n",
    "for meta in metascore:\n",
    "    metascores.append(meta.text)\n",
    "\n",
    "#genre\n",
    "m_genre = m_frame.findAll(\"span\", class_ = \"genre\")\n",
    "m_genre_list =[genre.text.strip().split(\"\\n\") for genre in m_genre]\n",
    "\n",
    "#duration\n",
    "m_duration = m_frame.findAll(\"span\", class_ = \"runtime\")\n",
    "m_duration_list = [dur.text.strip() for dur in m_duration]\n",
    "duration_list = []\n",
    "for dur in m_duration_list:\n",
    "    m = dur.split()\n",
    "    duration_list.append(m[0])\n",
    "\n",
    "#box office gross\n",
    "gross = []\n",
    "for i in range(1,101):\n",
    "    try:\n",
    "        bogross = driver.find_element_by_xpath('//*[@id=\"main\"]/div/div[3]/div[3]/div[' + str(i) + ']/div[2]/p[4]/span[5]')\n",
    "        bg = bogross.text\n",
    "        bg = bg.replace('$','').replace('M', '')\n",
    "        gross.append(bg)\n",
    "    except:\n",
    "        gross.append('Unavailable')\n",
    "\n",
    "ratings =[]\n",
    "for i in range (1, 101):\n",
    "    rating = driver.find_element_by_xpath( '//*[@id=\"main\"]/div/div[3]/div[3]/div[' + str(i) + ']/div[2]/div[1]/div[1]/span[2]')\n",
    "    ratings.append(rating.text)\n",
    "\n",
    "data = {\n",
    "    'Movie':m_names,\n",
    "    'Year of release': m_r_dates,\n",
    "    'Genre': m_genre_list,\n",
    "    'Directed by': directors,\n",
    "    'Starring': stars,\n",
    "    'Synopsis': m_desc_list,\n",
    "    'Box Office Gross in Million Dollars': gross,\n",
    "    'Duration in minutes':duration_list,\n",
    "    'IMDB User Rating': ratings,\n",
    "    'Metascore from Metacritic': metascore\n",
    "}   \n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('action.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['534.86', '292.58', '70.10', '187.71', '204.84', '227.47', '448.14', '171.48', '760.51', '132.07', '19.50', '23.64', '66.21', '167.45', '50.87', '154.06', '183.64', '83.01', '183.88', '197.17', '3.31', '4.91', '858.37', '70.51', '322.74', '206.85', '248.16', '38.40', '41.62', '146.28', '85.16', '188.37', '38.41', '0.71', '209.03', '180.98', '112.23', '31.49', '403.71', '145.00', '28.64', '26.95', '623.28', '107.83', '215.41', 'Unavailable', '25.03', '48.07', '111.55', '171.02', '176.24', '678.82', '42.30', '5.02', '232.64', '53.42', '139.31', '100.21', '25.63', '155.25', '304.36', '363.07', '77.91', '180.20', '65.21', '281.49', '66.49', '220.16', '333.18', '0.03', '412.56', '53.71', '350.13', '218.08', '257.73', '46.89', '1.20', '186.85', '0.03', '92.03', '43.04', '63.54', '128.26', '700.06', '155.06', '65.81', '137.69', '186.34', '652.27', '305.41', '59.74', '157.30', '305.41', '26.00', '47.21', '121.25', '134.07', '408.01', '144.80', '90.76']\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from time import sleep\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# selenium broswer \n",
    "url = \"https://www.imdb.com/list/ls009668579/\"\n",
    "#my_driver = r\"C:\\Users\\afrah\\OneDrive\\Documents\\01 STRIVE\\chromedriver.exe\" \n",
    "driver = webdriver.Chrome(r\"C:\\Users\\afrah\\OneDrive\\Documents\\01 STRIVE\\chromedriver.exe\")\n",
    "driver.get(url)\n",
    "sleep(1)\n",
    "\n",
    "gross = []\n",
    "for i in range(1,101):\n",
    "    try:\n",
    "        bogross = driver.find_element_by_xpath('//*[@id=\"main\"]/div/div[3]/div[3]/div[' + str(i) + ']/div[2]/p[4]/span[5]')\n",
    "        bg = bogross.text\n",
    "        bg = bg.replace('$','').replace('M', '')\n",
    "        gross.append(bg)\n",
    "    except:\n",
    "        gross.append('Unavailable')\n",
    "print(gross)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n"
   ]
  }
 ]
}